FROM llama3:latest

# This is a modelfile that fits my computer
PARAMETER num_thread 12
PARAMETER num_gpu 0

# ---- Context / memory ----
PARAMETER num_ctx 8192
PARAMETER num_keep 24

# ---- Sampling (balanced, clean output) ----
PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER top_k 40
PARAMETER repeat_penalty 1.1
PARAMETER repeat_last_n 256
PARAMETER num_predict -1
# PARAMETER seed 42   # (ok to leave this comment since it’s on its own line)

# ---- Llama 3 stop tokens (don’t remove) ----
PARAMETER stop <|start_header_id|>
PARAMETER stop <|end_header_id|>
PARAMETER stop <|eot_id|>
